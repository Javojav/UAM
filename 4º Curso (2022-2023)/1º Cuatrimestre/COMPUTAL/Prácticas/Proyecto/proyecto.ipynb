{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["iyCjsfa-Yxfi"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## Installing the enviroment"],"metadata":{"id":"iyCjsfa-Yxfi"}},{"cell_type":"code","source":["!rm -rf master.zip* nvcc4jupyter-master*\n","!wget https://github.com/andreinechaev/nvcc4jupyter/archive/refs/heads/master.zip\n","!unzip master.zip\n","!cd nvcc4jupyter-master; ls; python setup.py install"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i1jGpXx2Y1N4","executionInfo":{"status":"ok","timestamp":1671165103500,"user_tz":-60,"elapsed":1038,"user":{"displayName":"Daniel Cerrato Sánchez","userId":"10660784739789153592"}},"outputId":"7c6e0b96-5931-4508-9939-3712c0463d22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-16 04:31:41--  https://github.com/andreinechaev/nvcc4jupyter/archive/refs/heads/master.zip\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://codeload.github.com/andreinechaev/nvcc4jupyter/zip/refs/heads/master [following]\n","--2022-12-16 04:31:42--  https://codeload.github.com/andreinechaev/nvcc4jupyter/zip/refs/heads/master\n","Resolving codeload.github.com (codeload.github.com)... 20.205.243.165\n","Connecting to codeload.github.com (codeload.github.com)|20.205.243.165|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/zip]\n","Saving to: ‘master.zip’\n","\n","master.zip              [ <=>                ]   5.08K  --.-KB/s    in 0.002s  \n","\n","2022-12-16 04:31:42 (2.08 MB/s) - ‘master.zip’ saved [5201]\n","\n","Archive:  master.zip\n","aac710a35f52bb78ab34d2e52517237941399eff\n","   creating: nvcc4jupyter-master/\n"," extracting: nvcc4jupyter-master/.gitignore  \n","  inflating: nvcc4jupyter-master/README.md  \n","   creating: nvcc4jupyter-master/common/\n"," extracting: nvcc4jupyter-master/common/__init__.py  \n","  inflating: nvcc4jupyter-master/common/helper.py  \n","  inflating: nvcc4jupyter-master/nvcc_plugin.py  \n","  inflating: nvcc4jupyter-master/setup.py  \n","   creating: nvcc4jupyter-master/v1/\n"," extracting: nvcc4jupyter-master/v1/__init__.py  \n","  inflating: nvcc4jupyter-master/v1/v1.py  \n","   creating: nvcc4jupyter-master/v2/\n"," extracting: nvcc4jupyter-master/v2/__init__.py  \n","  inflating: nvcc4jupyter-master/v2/v2.py  \n","common\tnvcc_plugin.py\tREADME.md  setup.py  v1  v2\n","running install\n","running build\n","running build_py\n","creating build\n","creating build/lib\n","copying nvcc_plugin.py -> build/lib\n","creating build/lib/v2\n","copying v2/__init__.py -> build/lib/v2\n","copying v2/v2.py -> build/lib/v2\n","creating build/lib/v1\n","copying v1/__init__.py -> build/lib/v1\n","copying v1/v1.py -> build/lib/v1\n","creating build/lib/common\n","copying common/__init__.py -> build/lib/common\n","copying common/helper.py -> build/lib/common\n","running install_lib\n","creating /usr/local/lib/python3.8/dist-packages/common\n","copying build/lib/common/helper.py -> /usr/local/lib/python3.8/dist-packages/common\n","copying build/lib/common/__init__.py -> /usr/local/lib/python3.8/dist-packages/common\n","creating /usr/local/lib/python3.8/dist-packages/v2\n","copying build/lib/v2/__init__.py -> /usr/local/lib/python3.8/dist-packages/v2\n","copying build/lib/v2/v2.py -> /usr/local/lib/python3.8/dist-packages/v2\n","creating /usr/local/lib/python3.8/dist-packages/v1\n","copying build/lib/v1/v1.py -> /usr/local/lib/python3.8/dist-packages/v1\n","copying build/lib/v1/__init__.py -> /usr/local/lib/python3.8/dist-packages/v1\n","copying build/lib/nvcc_plugin.py -> /usr/local/lib/python3.8/dist-packages\n","byte-compiling /usr/local/lib/python3.8/dist-packages/common/helper.py to helper.cpython-38.pyc\n","byte-compiling /usr/local/lib/python3.8/dist-packages/common/__init__.py to __init__.cpython-38.pyc\n","byte-compiling /usr/local/lib/python3.8/dist-packages/v2/__init__.py to __init__.cpython-38.pyc\n","byte-compiling /usr/local/lib/python3.8/dist-packages/v2/v2.py to v2.cpython-38.pyc\n","byte-compiling /usr/local/lib/python3.8/dist-packages/v1/v1.py to v1.cpython-38.pyc\n","byte-compiling /usr/local/lib/python3.8/dist-packages/v1/__init__.py to __init__.cpython-38.pyc\n","byte-compiling /usr/local/lib/python3.8/dist-packages/nvcc_plugin.py to nvcc_plugin.cpython-38.pyc\n","running install_egg_info\n","Writing /usr/local/lib/python3.8/dist-packages/NVCCPlugin-0.0.2.egg-info\n"]}]},{"cell_type":"code","source":["# Crea carpeta src\n","%load_ext nvcc_plugin\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NhlU1M3-ZCXS","executionInfo":{"status":"ok","timestamp":1671165103502,"user_tz":-60,"elapsed":7,"user":{"displayName":"Daniel Cerrato Sánchez","userId":"10660784739789153592"}},"outputId":"991bf772-6eab-461d-bab7-a71c4356f220"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["created output directory at /content/src\n","Out bin /content/result.out\n"]}]},{"cell_type":"markdown","source":["## Generamos el codigo C++"],"metadata":{"id":"GbTBgf7oZ6aA"}},{"cell_type":"code","source":["!mkdir cuda\n","!rm -rf cuda/*"],"metadata":{"id":"-U2PwoCiC7lc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile cuda/GPU_multi.cu\n","#include <stdio.h>\n","#include <algorithm>\n","#include <iostream>\n","#include <sys/time.h>\n","#include <sstream>\n","#include <limits>\n","#include <cuda.h>\n","#include <cuda_runtime.h>\n","\n","using namespace std;\n","\n","#define BLOCK_SIZE 512\n","\n","__global__ void matrixMultiplicationKernel(int* mt1, int* mt2, int* result, int filas1, int columnas1, int columnas2) {\n","\n","    int fila = blockIdx.y*blockDim.y+threadIdx.y;\n","    int columna = blockIdx.x*blockDim.x+threadIdx.x;\n","\n","    //compruebo que no se haya salido de la matriz\n","    if (fila < filas1 && columna < columnas2) {\n","        int tmpSum = 0;\n","        // cada thread se encarga de un elemento\n","        for (int i = 0; i < columnas1; i++) {\n","            tmpSum += mt1[fila * columnas1 + i] * mt2[i * columnas2 + columna];\n","        }\n","        //guardamos la suma total en su posición\n","      result[fila * columnas2 + columna] = tmpSum;\n","    }\n","}\n","\n","int *multiplicaMatrices(int *mat1, int *mat2, int filas1, int comp, int columnas2){\n","  int *matRes = (int *)calloc(filas1 * columnas2, sizeof(int));\n","\n","  for (int i = 0; i < filas1; i++){\n","    for (int j = 0; j < columnas2; j++){\n","      for (int k = 0; k < comp; k++){\n","        matRes[i * columnas2 + j] += mat1[i * comp + k] * mat2[k * comp + j];\n","      }\n","    }\n","  }\n","  return matRes;\n","}\n","\n","\n","int main(){\n","  int numMatrices;\n","  struct timeval ini, fin;\n","\n","  do {\n","      //cout << \"Introduce el número de matrices (minimo 2): \";\n","      cin >> numMatrices;\n","      cin.clear();\n","      cin.ignore(numeric_limits<streamsize>::max(),'\\n');\n","  }while (numMatrices < 2);\n","  \n","  //matriz en cada fila tiene el vector de la matriz de ese índice\n","  int **matrices = (int **)calloc(numMatrices, sizeof(int *));\n","  int *arrayFilas = (int *)calloc(numMatrices, sizeof(int *));\n","  int *arrayColumnas = (int *)calloc(numMatrices, sizeof(int *));\n","\n","  for (int ind_matric=0; ind_matric!=numMatrices; ind_matric++){\n","      int filas, columnas;\n","      do{\n","        //cout << \"Introduce el número de filas y columnas recuerda que deben ser mayor que 0([filas] [columnas]): \";\n","        cin >> filas >> columnas;\n","        cin.clear();\n","        cin.ignore(numeric_limits<streamsize>::max(),'\\n');\n","      }while(filas<=0 || columnas<=0);\n","      \n","      if(ind_matric!=0){\n","        if(filas!=arrayColumnas[ind_matric-1]){\n","          cout<<\"No es posible esa multiplicación de matrices\";\n","          return 1;\n","        }\n","      }\n","      \n","      arrayFilas[ind_matric]=filas;\n","      arrayColumnas[ind_matric]=columnas;\n","      \n","      int *matriz = (int *)calloc(filas * columnas, sizeof(int));\n","      \n","      for(int fila=0; fila!=filas; fila++){\n","        //cout<<\"Introduzca la fila: \";\n","        string strFila;\n","        getline(cin, strFila);\n","        cin.clear();\n","        //int *arr = (int *)calloc(tam, sizeof(int)); //fila con los números\n","        \n","        istringstream ss(strFila); //hacemos un string stream para pasar de string a int\n","        string del;\n","   \n","        for(int aux=0; getline(ss, del, ' ') && aux!=columnas; aux++) { //con el getline separamos hasta el espacio\n","            matriz[aux + fila * columnas] = stoi(del); //convertimos de string a número\n","        }\n","      }\n","\n","      matrices[ind_matric]=matriz;\n","  }\n","  \n","  float timeCPU = 0.0;\n","  int *resMatrix = matrices[0];\n","  for (int i = 1; i < numMatrices; i++){\n","    gettimeofday(&ini,NULL);\n","    resMatrix = multiplicaMatrices(resMatrix, matrices[i], arrayFilas[0], arrayColumnas[i-1], arrayColumnas[i]);\n","    gettimeofday(&fin,NULL);\n","    timeCPU += ((fin.tv_sec*1000000+fin.tv_usec)-(ini.tv_sec*1000000+ini.tv_usec))*1.0/1000000.0;\n","  }\n","  printf(\"CPU = %f\\n\", timeCPU);\n","\n","  int *d_in1, *d_in2, *d_out;\n","  int *out, imparFlag;\n","  float timeGPU1 = 0.0;\n","\n","  resMatrix = matrices[0];\n","  for (int i = 1; i < numMatrices; i++){\n","\n","    // Alloc space for device copies\n","    cudaMalloc((void **)&d_in1, arrayFilas[0]*arrayColumnas[i-1]*sizeof(int));\n","    cudaMalloc((void **)&d_in2, arrayFilas[i]*arrayColumnas[i]*sizeof(int));\n","\n","    //resultado que tendrá filas del primero y columnas del segundo\n","    cudaMalloc((void **)&d_out, arrayFilas[0]*arrayColumnas[i]*sizeof(int));\n","\n","    // Copy to device\n","    cudaMemcpy(d_in1, resMatrix, arrayFilas[0]*arrayColumnas[i-1]*sizeof(int), cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_in2, matrices[i], arrayFilas[i]*arrayColumnas[i]*sizeof(int), cudaMemcpyHostToDevice);\n","\n","    //inicializamos la salida\n","    out = (int *)calloc(arrayFilas[0]*arrayColumnas[i], sizeof(int));\n","\n","    gettimeofday(&ini,NULL);\n","    matrixMultiplicationKernel<<<arrayFilas[0], arrayColumnas[i-1]>>>(d_in1, d_in2, d_out, arrayFilas[0], arrayColumnas[i-1], arrayColumnas[i]);\n","    gettimeofday(&fin,NULL);\n","    timeGPU1 += ((fin.tv_sec*1000000+fin.tv_usec)-(ini.tv_sec*1000000+ini.tv_usec))*1.0/1000000.0;\n","\n","    //Copiamos el resultado al host\n","    cudaMemcpy(out, d_out,  arrayFilas[0]*arrayColumnas[i]*sizeof(int), cudaMemcpyDeviceToHost);\n","    resMatrix = out;\n","\n","    cudaFree(d_in1); cudaFree(d_in2); cudaFree(d_out);\n","  }\n","  printf(\"GPU1 = %f\\n\", timeGPU1);\n","\n","  /*\n","  for(int i=0; i!=arrayFilas[0]; i++){\n","    for(int j=0; j!=arrayColumnas[numMatrices-1]; j++){\n","      printf(\"%d \" , resMatrix[i*arrayColumnas[numMatrices-1]+j]);\n","    }\n","    cout << \"\\n\";\n","  }\n","  cout << \"\\n\";\n","  */\n","  \n","  float timeGPU2 = 0.0;\n","  for ( ; numMatrices > 1; numMatrices/=2){\n","    if (numMatrices % 2 == 0)\n","      imparFlag = 0;\n","    else\n","      imparFlag = 1;\n","    for (int index = imparFlag; index < numMatrices; index += 2){\n","\n","      // Alloc space for device copies\n","      cudaMalloc((void **)&d_in1, arrayFilas[index]*arrayColumnas[index]*sizeof(int));\n","      cudaMalloc((void **)&d_in2, arrayFilas[index+1]*arrayColumnas[index+1]*sizeof(int));\n","\n","      //resultado que tendrá filas del primero y columnas del segundo\n","      cudaMalloc((void **)&d_out, arrayFilas[index]*arrayColumnas[index+1]*sizeof(int));\n","\n","      //inicializamos la salida\n","      out = (int *)calloc(arrayFilas[index]*arrayColumnas[index+1], sizeof(int));\n","\n","      // Copy to device\n","      cudaMemcpy(d_in1, matrices[index], arrayFilas[index]*arrayColumnas[index]*sizeof(int), cudaMemcpyHostToDevice);\n","      cudaMemcpy(d_in2, matrices[index+1], arrayFilas[index]*arrayColumnas[index+1]*sizeof(int), cudaMemcpyHostToDevice);\n","\n","      //int n_blocks = ceil(arrayFilas[index]*arrayColumnas[index+1]/BLOCK_SIZE);\n","      //dim3 threadsPerBlock (BLOCK_SIZE, BLOCK_SIZE);\n","      //dim3 blocksPerGrid (n_blocks,n_blocks);\n","\n","      gettimeofday(&ini,NULL);\n","      //llamo a la multiplicación de matrices\n","      matrixMultiplicationKernel<<<arrayFilas[index], arrayColumnas[index+1]>>>(d_in1, d_in2, d_out, arrayFilas[index], arrayColumnas[index], arrayColumnas[index+1]);\n","      gettimeofday(&fin,NULL);\n","\n","      timeGPU2 += ((fin.tv_sec*1000000+fin.tv_usec)-(ini.tv_sec*1000000+ini.tv_usec))*1.0/1000000.0;\n","\n","      //Copiamos el resultado al host\n","      cudaMemcpy(out, d_out,  arrayFilas[index]*arrayColumnas[index+1]*sizeof(int), cudaMemcpyDeviceToHost);\n","\n","      free(matrices[index]); free(matrices[index+1]);\n","      cudaFree(d_in1); cudaFree(d_in2); cudaFree(d_out);\n","\n","      matrices[index/2+imparFlag] = out;\n","      arrayFilas[index/2+imparFlag] = arrayFilas[index];\n","      arrayColumnas[index/2+imparFlag] = arrayColumnas[index+1];\n","    }\n","    numMatrices += imparFlag;\n","  }\n","\n","  printf(\"GPU2 = %f\\n\", timeGPU2);\n","  \n","  /*\n","  for(int i=0; i!=arrayFilas[0]; i++){\n","    for(int j=0; j!=arrayColumnas[0]; j++){\n","      printf(\"%d \" , matrices[0][i*arrayColumnas[0]+j]);\n","    }\n","    cout << \"\\n\";\n","  }\n","  cout << \"\\n\";\n","  */\n","\n","  return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671167301976,"user_tz":-60,"elapsed":492,"user":{"displayName":"Daniel Cerrato Sánchez","userId":"10660784739789153592"}},"outputId":"28cfde97-b085-4e7c-ca8a-2b9734bcbf7a","id":"dWIKz7W2hpDE"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting cuda/GPU_multi.cu\n"]}]},{"cell_type":"code","source":["from random import randint\n","\n","f = open(\"cuda/entrada.txt\", \"w\")\n","\n","numMatrices = 1000\n","f.write(str(numMatrices) + \"\\n\")\n","\n","exit()\n","\n","dimensions = [randint(10, 50) for _ in range(numMatrices + 1)]\n","for i in range(numMatrices):\n","  f.write(str(dimensions[i]) + \" \" + str(dimensions[i+1]) + \"\\n\")\n","  for _ in range(dimensions[i]):\n","    row = \"\"\n","    for _ in range(dimensions[i+1] - 1):\n","      row += str(randint(0, 5)) + \" \"\n","    row += str(randint(0, 5)) + \"\\n\"\n","    f.write(row)\n","\n","f.close()"],"metadata":{"id":"dXiYFkHEjINR","executionInfo":{"status":"ok","timestamp":1671168133782,"user_tz":-60,"elapsed":1167,"user":{"displayName":"Daniel Cerrato Sánchez","userId":"10660784739789153592"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!nvcc cuda/*.cu -o cuda/program\n","!./cuda/program < cuda/entrada.txt\n","!rm -rf ./cuda/program"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AdIIOWRSl9N3","executionInfo":{"status":"ok","timestamp":1671168146133,"user_tz":-60,"elapsed":3701,"user":{"displayName":"Daniel Cerrato Sánchez","userId":"10660784739789153592"}},"outputId":"3edf9463-0748-4b3f-9e9b-f7a2881ee108"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU = 0.392700\n","GPU1 = 0.006264\n","GPU2 = 0.007854\n"]}]}]}